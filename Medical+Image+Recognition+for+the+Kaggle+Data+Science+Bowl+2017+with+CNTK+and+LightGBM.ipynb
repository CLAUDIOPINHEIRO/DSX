{"nbformat": 4, "metadata": {"language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "nbconvert_exporter": "python", "file_extension": ".py", "name": "python", "version": "3.4.5"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "cells": [{"cell_type": "markdown", "source": "# Medical Image Recognition for the Kaggle Data Science Bowl 2017 with CNTK and LightGBM\n\nIn this notebook we will explain how to quickly start competing in the [Data Science Bowl 2017](https://www.kaggle.com/c/data-science-bowl-2017) and create a first submission. \n\nThe challenge of this year is lung cancer detection. The participants have to determine if a scan has cancerous lesions or not. All the information of the competition can be found in the [web page](https://www.kaggle.com/c/data-science-bowl-2017/rules). We provide an example of how to detect cancerous scans using the deep learning library [CNTK](https://github.com/Microsoft/CNTK) and the gradient boosting library [LightGBM](https://github.com/Microsoft/LightGBM/), both opensourced by Microsoft.  \n\nIn the notebook we are going to generate automatic features from the images using a pretrained Convolutional Neural Network (CNN) using CNTK. CNNs are great automatic feature generators, which is the secret sauce of deep learning. Therefore, we can take the weights of the penultimate layer of the pretrained network and use it an image featurizer. \n\nOnce we have the features, and after performing some basic feature engineering, we can feed them to a boosted decision tree using the LightGBM library. The resulting classifier obtained a **score of 0.55979** in the competition leaderboard. \n\n## Azure Virtual Machines\n\n\nWe believe that for this competition speed is crucial. In that sense CNTK outperforms many other frameworks, as it is shown in this [recent paper](https://arxiv.org/abs/1608.07249). Also, LightGBM [performs better](https://github.com/Microsoft/LightGBM/wiki/Experiments#comparison-experiment) than other similar frameworks. This two solutions, mixed with Azure's high-performance [GPU Virtual Machines](https://azure.microsoft.com/en-us/pricing/details/virtual-machines/series/#n-series), can provide a cheap and powerful environment to compete in the Data Science Bowl. \n\nOf all the options of VMs that Microsoft provides, it is interesting to highlight the Data Science Virtual Machine (DSVM), available for [Windows](https://azure.microsoft.com/en-gb/marketplace/partners/microsoft-ads/standard-data-science-vm/) and [Linux](https://azure.microsoft.com/en-gb/marketplace/partners/microsoft-ads/linux-data-science-vm/). The DSVM is a product targeted to Data Scientists and machine learning professionals, that has many popular data science and other tools pre-installed and pre-configured to jump-start building intelligent applications for advanced analytics. All the information of the tools available in the DSVM can be found in its [web page](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-virtual-machine-overview#whats-included-in-the-data-science-vm).  \n\n\n\n## Requirements\n\nThe DSVM comes with CNTK preinstalled, so you can start with it to set up the environment faster. However, for this tutorial we are going to assume that you are in a standard Azure VM. You need to install the following frameworks. \n\n- **CUDA**: [CUDA 8.0 RC1](https://developer.nvidia.com/cuda-toolkit) can be downloaded from NVIDIA web (registration is required). If you are in Linux, you also need to download CUDA Patch 1 from the website. The patch adds support for gcc 5.4 as one of the host compilers.\n- **cuDNN**: [cuDNN 5.1](https://developer.nvidia.com/cudnn) (registration with NVIDIA required). \n- **MKL**: Intel\u00c2\u00b4s Math Kernel Library (MKL) version 11.3 update 3 (registration with Intel required). \n- **Anaconda**: [Anaconda 4.2.0](https://www.continuum.io/downloads) is strongly recommended as the default python framework. It provides support for conda environments and jupyter notebooks. \n- **OpenCV**: [OpenCV](http://opencv.org/downloads.html) is the most popular library of computer vision. If you are an experimented programer you can try to build and install from source. Otherwise it is easier to install via conda with this command: `conda install -c https://conda.binstar.org/menpo opencv`.\n- **Scikit-learn**: [Scikit-learn 0.18](http://scikit-learn.org/stable/) is a very popular machine learning library for python. It can be easily install via `pip`: `pip install scikit-learn`.\n- **CNTK**: [CNTK 2.0beta9](https://github.com/Microsoft/CNTK/wiki/Setup-CNTK-on-your-machine) for python. You can build from source but it is faster to install the precompiled binaries. To benefit from the fastest experience we recomend to enable [1-bit SQG](https://github.com/Microsoft/CNTK/wiki/Enabling-1bit-SGD), which is specially fast when using multi-GPU in a multi-server. \n- **LightGBM**: [LightGBM](https://github.com/Microsoft/LightGBM/wiki/Installation-Guide) can be easily installed with CMake. Also you have to install the [python biddings](https://github.com/Microsoft/LightGBM/tree/master/python-package).\n- **Pretrained ResNet with CNTK**: We are going to use a pretrained convolutional neural network (CNN) with the [ResNet architecture](https://arxiv.org/abs/1512.03385). This configuration, developed by Microsoft Research, was the first CNN to surpass the human level performance in image classification. The network was trained in the [ImageNet dataset](http://image-net.org/) and can be downloaded [here](https://migonzastorage.blob.core.windows.net/deep-learning/models/cntk/imagenet/ResNet_152.model).\n\n## Data\nIn addition to the libraries you have to download the [data](https://www.kaggle.com/c/data-science-bowl-2017/data) of the competition. The images are in [DICOM](https://en.wikipedia.org/wiki/DICOM) format and consist of a group of horizontal slices of the thorax for each patient. This is one slice:\n\n<p align=\"center\">\n<img src=\"https://migonzastorage.blob.core.windows.net:443/projects/data_science_bowl_2017/sample_mri_slice.png\" alt=\"sample\" width=\"30%\"/>\n<\/p>\n\nThe biggest file `stage1.7z` occupies 67Gb. When the file is uncompressed it occupies 141Gb. In case you need more space, you ca easily attach an external drive to your Azure VM. Here you can find the instructions for [Windows](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-windows-attach-disk-portal?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) and [Linux](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-linux-attach-disk-portal?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json). \n", "metadata": {"collapsed": true}}, {"cell_type": "code", "outputs": [], "source": "#Load libraries\nimport sys,os\nimport numpy as np\nimport dicom\nimport glob\nfrom matplotlib import pyplot as plt\nimport cv2\nimport pandas as pd\nimport time\nfrom sklearn import cross_validation\nfrom cntk import load_model\nfrom cntk.ops import combine\nfrom cntk.io import MinibatchSource, ImageDeserializer, StreamDef, StreamDefs\nfrom lightgbm.sklearn import LGBMRegressor\n\nprint(\"System version:\", sys.version, \"\\n\")\nprint(\"CNTK version:\",pkg_resources.get_distribution(\"cntk\").version)", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "## Function definition\n\nThe first step is to set the path and variables.", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "#Put here the number of your experiment\nEXPERIMENT_NUMBER = '0042' \n\n#Put here the path to the downloaded ResNet model\nMODEL_PATH='/datadrive/installer/cntk/Examples/Image/PretrainedModels/ResNet_152.model' \n\n#Put here the path where you downloaded all kaggle data\nDATA_PATH='/datadrive/kaggle/datascience_bowl_2017/'\n\n# Path and variables\nSTAGE1_LABELS=DATA_PATH + 'stage1_labels.csv'\nSTAGE1_SAMPLE_SUBMISSION=DATA_PATH + 'stage1_sample_submission.csv'\nSTAGE1_FOLDER=DATA_PATH + 'stage1/'\nFEATURE_FOLDER=DATA_PATH + 'features/features' + EXPERIMENT_NUMBER + '/'\nSUBMIT_OUTPUT='submit' + EXPERIMENT_NUMBER + '.csv'\n", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "This is a timer class. ", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "# Timer class\nclass Timer(object):\n    def __enter__(self):\n        self.start()\n        return self\n\n    def __exit__(self, *args):\n        self.stop()\n\n    def start(self):\n        self.start = time.clock()\n\n    def stop(self):\n        self.end = time.clock()\n        self.interval = self.end - self.start", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "This couple of functions collect the images, perform an histogram equalization and are resized to the ImageNet standard size: `224x224`. Also, the images in ImageNet are color images, with three channels, RGB, however, the images from the data science competition are in gray scale. A quick way to adapt the cancer images to the format of ImageNet is to pack them in groups of three. That is what we are doing in the function `get_data_id`. ", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "def get_3d_data(path):\n    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n    slices.sort(key=lambda x: int(x.InstanceNumber))\n    return np.stack([s.pixel_array for s in slices])", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "code", "outputs": [], "source": "def get_data_id(path, plot_data=False):\n    sample_image = get_3d_data(path)\n    sample_image[sample_image == -2000] = 0\n    if plot_data:\n        f, plots = plt.subplots(4, 5, sharex='col', sharey='row', figsize=(10, 8))\n\n    batch = []\n    cnt = 0\n    dx = 40\n    ds = 512\n    for i in range(0, sample_image.shape[0] - 3, 3):\n        tmp = []\n        for j in range(3):\n            img = sample_image[i + j]\n            img = 255.0 / np.amax(img) * img\n            img = cv2.equalizeHist(img.astype(np.uint8))\n            img = img[dx: ds - dx, dx: ds - dx]\n            img = cv2.resize(img, (224, 224))\n            tmp.append(img)\n\n        tmp = np.array(tmp)\n        batch.append(np.array(tmp))\n\n        if plot_data:\n            if cnt < 20:\n                plots[cnt // 5, cnt % 5].axis('off')\n                plots[cnt // 5, cnt % 5].imshow(tmp[0,:,:], cmap='gray')\n            cnt += 1\n\n    if plot_data: plt.show()\n        \n    batch = np.array(batch, dtype='int')\n    return batch", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "In this sample experiment, we used the last layer of a pretrained ResNet network with 152 layers as featurizer to extract features. CNTK provides other pretrained networks that you can test like [AlexNet](https://www.cntk.ai/Models/AlexNet/AlexNet.model), [AlexNet with Batch Normalization](https://www.cntk.ai/Models/AlexNet/AlexNetBS.model) and [ResNet with 18 layers](https://www.cntk.ai/Models/ResNet/ResNet_18.model).  \n \nPlease note the name of the last layer of pretrained network is named as `z.x` in CNTK, which should be specified when use for featurizer. def get_extractor():\n    node_name = \"z.x\"\n    loaded_model  = load_model(MODEL_PATH)\n    node_in_graph = loaded_model.find_by_name(node_name)\n    output_nodes  = combine([node_in_graph.owner])\n    return output_nodes", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "def get_extractor():\n    node_name = \"z.x\"\n    loaded_model  = load_model(MODEL_PATH)\n    node_in_graph = loaded_model.find_by_name(node_name)\n    output_nodes  = combine([node_in_graph.owner])\n    return output_nodes", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "This function is responsible of computing the features. For that, given a batch of images we just compute the forward propagation in the network, which can be done by typing `net.eval(batch)`. The resulting features are saved as a numpy array.", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "def calc_features(verbose=False):\n    net = get_extractor()\n    for folder in glob.glob(STAGE1_FOLDER+'*'):\n        foldername = os.path.basename(folder)\n        if os.path.isfile(FEATURE_FOLDER+foldername+'.npy'):\n            if verbose: print(\"Features in %s already computed\" % (FEATURE_FOLDER+foldername))\n            continue\n        batch = get_data_id(folder)\n        if verbose:\n            print(\"Batch size:\")\n            print(batch.shape)\n        feats = net.eval(batch)\n        if verbose:\n            print(feats.shape)\n            print(\"Saving features in %s\" % (FEATURE_FOLDER+foldername))\n        np.save(FEATURE_FOLDER+foldername, feats)", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "Once we have the features computed we can feed them in a boosted tree. Each numpy array contains the features of the images corresponding to one patient, and they are labelled as positive (the patient has cancer) or negative (the patient doesn't have cancer). We can average and flatten all the features to obtain a one dimensional vector representing one observation. The metric use in the tree optimization is L2, there are [other metrics](https://github.com/Microsoft/LightGBM/blob/7426ac3cbd9ae27b5d734a54e5e9880623beea43/docs/Parameters.md#metric-parameters) that can be applied. ", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "def train_lightgbm():\n    df = pd.read_csv(STAGE1_LABELS)\n\n    x = np.array([np.mean(np.load(FEATURE_FOLDER+'%s.npy' % str(id)), axis=0).flatten() for id in df['id'].tolist()])\n    y = df['cancer'].as_matrix()\n\n    trn_x, val_x, trn_y, val_y = cross_validation.train_test_split(x, y, random_state=42, stratify=y,\n                                                                   test_size=0.20)\n    clf = LGBMRegressor(max_depth=50,\n                        num_leaves=21,\n                        n_estimators=5000,\n                        min_child_weight=1,\n                        learning_rate=0.001,\n                        nthread=24,\n                        subsample=0.80,\n                        colsample_bytree=0.80,\n                        seed=42)\n    clf.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], verbose=True, eval_metric='l2', early_stopping_rounds=300)\n    return clf", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "We create a wrapper of the training function. That way we make the code extendable in case another user wants to try other training method.  ", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "def compute_training(verbose=True):\n    with Timer() as t:\n        clf = train_lightgbm()\n    if verbose: print(\"Training took %.03f sec.\\n\" % t.interval)\n    return clf", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "Once we have trained the model, we can use it to compute the results in the validation set. Again, this function is easily extendable in case a person want to use another model (always the scikit-learn interface `predict` has to be maintained).", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "def compute_prediction(clf, verbose=True):    \n    df = pd.read_csv(STAGE1_SAMPLE_SUBMISSION)\n    x = np.array([np.mean(np.load((FEATURE_FOLDER+'%s.npy') % str(id)), axis=0).flatten() for id in df['id'].tolist()])\n    \n    with Timer() as t:\n        pred = clf.predict(x)\n    if verbose: print(\"Prediction took %.03f sec.\\n\" % t.interval)\n    df['cancer'] = pred\n    return df", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "We finally save the results as a csv file.", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "def save_results(df):\n    df.to_csv(SUBMIT_OUTPUT, index=False)", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "## Execution\n\nPlot an example of images with cancer. The plot shows horizontal slices of the thorax.", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "path_cancer = STAGE1_FOLDER + 'fe45462987bacc32dbc7126119999392'\ndata_batch = get_data_id(path_cancer, True)\nprint(\"Data batch size: \", data_batch.shape)", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "Resulting image: \n<p align=\"center\">\n<img src=\"https://migonzastorage.blob.core.windows.net:443/projects/data_science_bowl_2017/output_10_0.png\" alt=\"image with cancer\" width=\"60%\"/>\n<\/p>\nData batch size:  (80, 3, 224, 224)", "metadata": {}}, {"cell_type": "markdown", "source": "Plot example of images without cancer.", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "path_no_cancer = STAGE1_FOLDER + 'ffe02fe7d2223743f7fb455dfaff3842'\ndata_batch = get_data_id(path_no_cancer, True)\nprint(\"Data batch size: \", data_batch.shape)", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "Resulting image: \n<p align=\"center\">\n<img src=\"https://migonzastorage.blob.core.windows.net:443/projects/data_science_bowl_2017/output_12_0.png\" alt=\"image with cancer\" width=\"60%\"/>\n<\/p>\n\nData batch size:  (57, 3, 224, 224)", "metadata": {}}, {"cell_type": "markdown", "source": "Compute features.", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "%%time\n# Calculate features\ncalc_features(verbose=False)", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "Train the boosted tree. We train the tree with early stoping of 300 rounds, which means that the optimization will stop if the validation score doesn't improve for 300 rounds. ", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "%%time\nclf = compute_training(verbose=True)", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "Result:\n\nTrain until valid scores didn't improve in 300 rounds.\n\n[1]\tvalid_0's l2: 0.510452\n\n[2]\tvalid_0's l2: 0.510308\n\n[3]\tvalid_0's l2: 0.510153\n\n[4]\tvalid_0's l2: 0.509996\n\n[5]\tvalid_0's l2: 0.509844\n\n[6]\tvalid_0's l2: 0.509727\n\n[7]\tvalid_0's l2: 0.509584\n\n[8]\tvalid_0's l2: 0.509435\n\n[9]\tvalid_0's l2: 0.50928\n\n\n[10]\tvalid_0's l2: 0.509176\n\n...\n\n...\n\n...\n\n...\n\n[2570]\tvalid_0's l2: 0.435983\n\n[2571]\tvalid_0's l2: 0.435982\n\n[2572]\tvalid_0's l2: 0.435979\n\nEarly stopping, best iteration is:\n\n[2272]\tvalid_0's l2: 0.435508\n\nTraining took 1278.461 sec.\n\nCPU times: user 20min 47s, sys: 31.3 s, total: 21min 18s\nWall time: 59.6 s", "metadata": {}}, {"cell_type": "markdown", "source": "Compute predictiondf = compute_prediction(clf)\nprint(\"Results:\")\ndf.head()", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "df = compute_prediction(clf)\nprint(\"Results:\")\ndf.head()", "metadata": {"collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": "Save results to csv. ", "metadata": {}}, {"cell_type": "code", "outputs": [], "source": "save_results(df)", "metadata": {"collapsed": false}, "execution_count": null}, {"cell_type": "markdown", "source": "## Alternative routes and improvements\nThis notebook is just an example of what you can do with CNTK and LightGBM. Here we present some alternative routes that you can implement based on this script:\n\n- Use other pretrained CNNs: As previously mentioned you can try other networks like [AlexNet](https://www.cntk.ai/Models/AlexNet/AlexNet.model), [AlexNet with Batch Normalization](https://www.cntk.ai/Models/AlexNet/AlexNetBS.model) and [ResNet with 18 layers](https://www.cntk.ai/Models/ResNet/ResNet_18.model). \n- Use a customized network: The CNN we use is trained in ImageNet. Another option is to train the network directly with the cancer images. For that you can take a look at the [image classification tutorials](https://github.com/Microsoft/CNTK/tree/release/2.0.beta9.0/Examples/Image/Classification) of CNTK. A trick that might speed up the convergence is to initialize the weights with a pretrained model (like we are doing in the notebook). \n- Perform image augmentation: You can try to increment the training set by performing transformations in the images. For that you can apply different filters or rotate them.\n- Use a customize network with 3D images: CNTK allows [3D convolutions](https://github.com/Microsoft/CNTK/wiki/Convolution). On GPU, 1D, 2D and 3D convolutions will use cuDNN (fast), all other convolutions will use reference engine (slow). You can create a CNN that accepts 3D images. \n- Try tunning the parameters of the boosted tree: You can try to tune the parameters of the tree. For that LightGBM implements the sklearn function `GridSearchCV`. Here you have an [example](https://github.com/Microsoft/LightGBM/blob/b0f7aa508a373b16adbda6cbe66b188a014964d8/examples/python-guide/sklearn_example.py).\n- Try some feature engineering: Before training the tree, the features are averaged. You can try to feed the tree without this operation or try a different one.\n", "metadata": {}}, {"cell_type": "markdown", "source": "### Acknowledgements\n\nThis notebook is based on this [script published in kaggle](https://www.kaggle.com/hoaphumanoid/data-science-bowl-2017/cntk-and-lightgbm-quick-start). It was also based in this [other script](https://www.kaggle.com/drn01z3/data-science-bowl-2017/mxnet-xgboost-baseline-lb-0-57). ", "metadata": {}}], "nbformat_minor": 0}