{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting churn with the SPSS random tree algorithm\n",
    "\n",
    "This Scala 2.10 notebook shows you how to create a predictive model of churn rate by using IBM SPSS Algorithm on Apache Spark version 1.6. You'll learn how to create an SPSS random tree model by using the IBM SPSS Machine Learning API, and how to view the model with IBM SPSS Model Viewer.\n",
    "\n",
    "Because it consists of multiple classification and regression trees (CART), you can use random tree algorithms to generate accurate predictive models and solve complex classification and regression problems. Each tree develops from a bootstrap sample that is produced by resampling the original data points with replacement data. During the resampling phase, the best split variable is selected for each node from a specified smaller number of variables that are drawn randomly from the full set of variables. Each tree grows without pruning and then, during the scoring phase, the random tree algorithm aggregates tree scores by majority voting (for classification) or average (for regression).\n",
    "\n",
    "In this notebook, you'll create a model with telecommunications data to predict when its customers will leave for a competitor, so that you can take some action to retain the customer.\n",
    "    \n",
    "To get the most out of this notebook, you should have some familiarity with the Scala programming language.\n",
    "\n",
    "## Contents \n",
    "This notebook contains the following main sections:\n",
    "\n",
    "1. [Load the Telco Churn data to the cloud data repository.](#overview)\n",
    "1. [Prepare the data.](#prepare)\n",
    "1. [Configure the RandomTrees model.](#configure) \n",
    "1. [View the model.](#view)\n",
    "1. [Summary and next steps.](#next)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## 1. Load the Telco Churn data to the cloud data repository.\n",
    "Telco Churn is a hypothetical data file that concerns a telecommunications company's efforts to reduce turnover in its customer base. Each case corresponds to a separate customer and it records various demographic and service usage information. Before you can work with the data, you must use the URL to get the telco.csv and telco_Feb.csv files from the GitHub repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val link_telco = \"https://raw.githubusercontent.com/AlgorithmDemo/SampleData/master/telco.csv\"\n",
    "\n",
    "import sys.process._\n",
    "import java.net.URL\n",
    "import java.io.File\n",
    "new URL(link_telco) #> new File(\"telco.csv\") !!\n",
    "\n",
    "val link_telco_Feb = \"https://raw.githubusercontent.com/AlgorithmDemo/SampleData/master/telco_Feb.csv\"\n",
    "\n",
    "import sys.process._\n",
    "import java.net.URL\n",
    "import java.io.File\n",
    "new URL(link_telco_Feb) #> new File(\"telco_Feb.csv\") !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare\"></a>\n",
    "## 2. Prepare the data.\n",
    "\n",
    "After uploading the CSV files that contain the data, you must create a SQLContext, put the data from the telco.scv file into a Spark DataFrame, and show the first row in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "\n",
    "val dfTelco = sqlContext.\n",
    "    read.\n",
    "    format(\"com.databricks.spark.csv\").\n",
    "    option(\"header\", \"true\").\n",
    "    option(\"inferschema\", \"true\").\n",
    "    load(\"telco.csv\")\n",
    "\n",
    "dfTelco.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Review the data. Print the schema of the DataFrame to look at what kind of data you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTelco.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create a DataFrame for the telco_Feb.csv data. You'll use this year's data to build the model, and use the February data for accuracy value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val dfTelcoFeb = sqlContext.\n",
    "    read.\n",
    "    format(\"com.databricks.spark.csv\").\n",
    "    option(\"header\", \"true\").\n",
    "    option(\"inferschema\", \"true\").\n",
    "    load(\"telco_Feb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"configure\"></a>\n",
    "## 3. Configure the RandomTrees model.\n",
    "\n",
    "By running this portion of the code, you create the random trees estimator, import the libraries, and set the ordinal and nominal variables. Because no inputFieldList value is set, all fields except the target, frequency, and analysis weight fields are treated as input fields. To make the random tree model build faster, set the number of trees to 10 instead of the default value, which is 100. Finally, you must specify the churn target field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import com.ibm.spss.ml.classificationandregression.ensemble.RandomTrees\n",
    "import com.ibm.spss.ml.utils.DataFrameImplicits.DataFrameEnrichImplicitsClass\n",
    "\n",
    "val ordinal = Array(\"ed\")\n",
    "val nominal = Array(\"region\",\n",
    "     \"marital\",\n",
    "     \"retire\",\n",
    "     \"gender\",\n",
    "     \"tollfree\",\n",
    "     \"equip\",\n",
    "     \"callcard\",\n",
    "     \"wireless\",\"multline\",\n",
    "     \"voice\",\"pager\",\"internet\",\"callid\",\"callwait\",\"forward\",\"confer\",\n",
    "     \"ebill\",\n",
    "     \"custcat\",\n",
    "     \"churn\"\n",
    "   )\n",
    "val srf = RandomTrees().setTargetField(\"churn\").setNumTrees(10)\n",
    "val srfModel = srf.fit(dfTelco.setNominalMeasure(nominal,true).setOrdinalMeasure(ordinal,true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the prediction and get your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val predResult = srfModel.transform(dfTelcoFeb)\n",
    "val predResultNew = predResult.withColumn(\"prediction\", predResult(\"prediction\").cast(\"double\")).\n",
    "    withColumn(\"churn\", predResult(\"churn\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the accuracy result, use the Apache Spark **MulticlassClassificationEvaluator** function. Notice that the accuracy is above 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "val evaluator = new MulticlassClassificationEvaluator().setLabelCol(\"churn\").setMetricName(\"precision\")\n",
    "val acc_result = evaluator.evaluate(predResultNew)\n",
    "println(s\"acc_result:$acc_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"view\"></a>\n",
    "## 4. View the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the random trees model result.\n",
    "To see the result, import the IBM SPSS Model Viewer, which you can use to explore different views of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import com.ibm.spss.scala.ModelViewer\n",
    "kernel.magics.html(ModelViewer.toHTML(srfModel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Export the XML files (PMML, StatXML) for other detail statistics.\n",
    "By exporting your results to different formats, such as Predictive Model Markup Language (PMML) or statXML format you can share your statistical analyses outside of IBM Data Science Experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import java.io.{File, PrintWriter}\n",
    "\n",
    "srfModel.toPMML(\"randomTrees_pmml.xml\")\n",
    "val statXML = srfModel.statXML()\n",
    "new PrintWriter(\"StatXML.xml\") {\n",
    "      write(statXML)\n",
    "      close\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"next\"></a>\n",
    "# Summary and next steps\n",
    "You have created a predictive model of churn rate by using IBM SPSS Algorithm on Apache Spark. Now you can create a different model to compare model evaluations, such as the test of model effects, residuals, and so on. See [SPSS documentation](https://apsportal.ibm.com/docs/content/kc_gen/integrations-gen2.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Wang Zhiyuan and Yu Wenpei are SPSS Algorithm Engineers at IBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Copyright Â© 2017 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10 with Spark 1.6",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "name": "scala"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}